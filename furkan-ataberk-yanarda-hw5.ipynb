{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":90855,"databundleVersionId":10624053,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:53:08.864011Z","iopub.execute_input":"2025-01-12T19:53:08.864249Z","iopub.status.idle":"2025-01-12T19:53:09.160605Z","shell.execute_reply.started":"2025-01-12T19:53:08.864227Z","shell.execute_reply":"2025-01-12T19:53:09.159741Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Data Preparation\n\nOur data directory is in a form that keras image generator's flow.from.directory method. So I will use that for creating image data for my model. Generally, it is better to augment(zoom, twist, reflect, etc.) the data in ImageDataGenerator() to help the model to generalize better. However, since there are so few data whatever options I tried the model started to underfit. So I won't touch the data.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Paths to train and test directories\ntrain_dir = '/kaggle/input/math482-2024-2025-1-hw-05/train/train'\ntest_dir = '/kaggle/input/math482-2024-2025-1-hw-05/test/test'\n\n# Create a DataFrame for the test dataset\ntest_files = [f for f in os.listdir(test_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\ntest_df = pd.DataFrame({'filename': test_files})\n\n# Data generators\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2  # Reserve 20% for validation\n\n)\n\n\n\ntest_datagen = ImageDataGenerator(rescale=1./255)  # Normalize test images\n\n# Train data loader\ntrain_data = datagen.flow_from_directory(\n    train_dir,\n    target_size=(128, 128),  # Resize images\n    batch_size=16,\n    class_mode='categorical', # Classes are categorical\n    subset='training',\n)\n\nval_data = datagen.flow_from_directory(\n    train_dir,\n    target_size=(128, 128),  # Resize images\n    batch_size=16,\n    class_mode='categorical', # Classes are categorical\n    subset='validation',\n)\n\n# Test data loader (from DataFrame)\ntest_df['filepath'] = test_df['filename'].apply(lambda x: os.path.join(test_dir, x))\n\ntest_data = test_datagen.flow_from_dataframe(\n    test_df,\n    x_col='filepath',  # Column with file paths\n    y_col=None,        # Test data has no labels\n    target_size=(128, 128),  # Resize images\n    batch_size=16,\n    class_mode=None,   # No labels for test data\n    shuffle=False      # Ensure consistent order for predictions\n)\n","metadata":{"trusted":true,"execution":{"iopub.execute_input":"2025-01-12T19:53:09.161878Z","iopub.status.idle":"2025-01-12T19:53:20.125842Z","shell.execute_reply.started":"2025-01-12T19:53:09.161842Z","shell.execute_reply":"2025-01-12T19:53:20.125138Z"}},"outputs":[{"name":"stdout","text":"Found 1280 images belonging to 6 classes.\nFound 320 images belonging to 6 classes.\nFound 400 validated image filenames.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Model Building(CNN)\nI am creating a CNN with 3 convolution layer. Normally, this much of a convolution layer causes the model to overfit. But, I implemented two dropout layers which eliminates %50 of the neurons and L2 regularization to adjust the weights in a way that prevents overfitting.  ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import datasets,layers,models,regularizers\n\nfrom tensorflow.keras import Input\n\nmodel = models.Sequential([\n    Input(shape=(128, 128, 3)),\n    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n\n    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    \n    layers.Dropout(0.5),\n    \n    layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    \n    \n    \n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(6, activation='softmax')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:53:20.126632Z","iopub.execute_input":"2025-01-12T19:53:20.127169Z","iopub.status.idle":"2025-01-12T19:53:21.182820Z","shell.execute_reply.started":"2025-01-12T19:53:20.127141Z","shell.execute_reply":"2025-01-12T19:53:21.181973Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"I will use Adam optimizer to find optimal weights classes","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\nmodel.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:53:21.183679Z","iopub.execute_input":"2025-01-12T19:53:21.183935Z","iopub.status.idle":"2025-01-12T19:53:21.198641Z","shell.execute_reply.started":"2025-01-12T19:53:21.183889Z","shell.execute_reply":"2025-01-12T19:53:21.197858Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Training the Model\nI shall use early stopping because I intend to train the model for high number of epochs. If the validation loss doesnt improve in 20 epoch, the model training will stop and it will revert back to the best weights. This prevents overfitting.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',  # Monitor validation loss\n    patience=20,          # Stop if no improvement for 5 epochs\n    restore_best_weights=True  # Restore model to the best weights\n)\n\nhistory = model.fit(\n    train_data,\n    validation_data=val_data,  # Add validation data\n    epochs=50,\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:53:21.199483Z","iopub.execute_input":"2025-01-12T19:53:21.199722Z","iopub.status.idle":"2025-01-12T19:54:37.467461Z","shell.execute_reply.started":"2025-01-12T19:53:21.199690Z","shell.execute_reply":"2025-01-12T19:54:37.466749Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.1674 - loss: 2.0632 - val_accuracy: 0.2000 - val_loss: 1.8753\nEpoch 2/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.2001 - loss: 1.8659 - val_accuracy: 0.2000 - val_loss: 1.8492\nEpoch 3/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.1874 - loss: 1.8494 - val_accuracy: 0.2000 - val_loss: 1.8354\nEpoch 4/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.2233 - loss: 1.8101 - val_accuracy: 0.2062 - val_loss: 1.8221\nEpoch 5/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.2027 - loss: 1.8215 - val_accuracy: 0.2000 - val_loss: 1.8138\nEpoch 6/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.1750 - loss: 1.8149 - val_accuracy: 0.2094 - val_loss: 1.8090\nEpoch 7/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.1704 - loss: 1.8093 - val_accuracy: 0.1969 - val_loss: 1.8077\nEpoch 8/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.1921 - loss: 1.7893 - val_accuracy: 0.2094 - val_loss: 1.8039\nEpoch 9/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.2308 - loss: 1.7840 - val_accuracy: 0.2125 - val_loss: 1.7999\nEpoch 10/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.2173 - loss: 1.7700 - val_accuracy: 0.2188 - val_loss: 1.8019\nEpoch 11/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.2195 - loss: 1.7612 - val_accuracy: 0.1813 - val_loss: 1.8285\nEpoch 12/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.2432 - loss: 1.7267 - val_accuracy: 0.2000 - val_loss: 1.8151\nEpoch 13/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.2163 - loss: 1.7345 - val_accuracy: 0.2031 - val_loss: 1.8305\nEpoch 14/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.2659 - loss: 1.6937 - val_accuracy: 0.1875 - val_loss: 1.8923\nEpoch 15/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.2654 - loss: 1.6864 - val_accuracy: 0.1844 - val_loss: 1.8583\nEpoch 16/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.2861 - loss: 1.6525 - val_accuracy: 0.1844 - val_loss: 1.9338\nEpoch 17/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.3027 - loss: 1.6274 - val_accuracy: 0.1844 - val_loss: 2.0010\nEpoch 18/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.3590 - loss: 1.5712 - val_accuracy: 0.1750 - val_loss: 2.0020\nEpoch 19/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.3308 - loss: 1.5460 - val_accuracy: 0.1781 - val_loss: 2.0690\nEpoch 20/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.3191 - loss: 1.5291 - val_accuracy: 0.1781 - val_loss: 2.1080\nEpoch 21/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.4071 - loss: 1.4966 - val_accuracy: 0.1969 - val_loss: 2.1463\nEpoch 22/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.3884 - loss: 1.4592 - val_accuracy: 0.1937 - val_loss: 2.2568\nEpoch 23/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.4086 - loss: 1.4335 - val_accuracy: 0.1875 - val_loss: 2.3707\nEpoch 24/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.4379 - loss: 1.3716 - val_accuracy: 0.1875 - val_loss: 2.3367\nEpoch 25/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.4617 - loss: 1.3715 - val_accuracy: 0.1906 - val_loss: 2.6129\nEpoch 26/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.4539 - loss: 1.3519 - val_accuracy: 0.1562 - val_loss: 2.5448\nEpoch 27/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5015 - loss: 1.2354 - val_accuracy: 0.1875 - val_loss: 2.6931\nEpoch 28/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.4817 - loss: 1.2506 - val_accuracy: 0.1562 - val_loss: 2.7095\nEpoch 29/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5437 - loss: 1.1713 - val_accuracy: 0.1813 - val_loss: 3.0184\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Predict on test data\npredictions = model.predict(test_data)\n\n# Convert predictions to class indices\npredicted_classes = predictions.argmax(axis=1)\n\n# Map class indices to class labels\nclass_labels = list(train_data.class_indices.keys())\npredicted_labels = [class_labels[i] for i in predicted_classes]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:54:37.468491Z","iopub.execute_input":"2025-01-12T19:54:37.468786Z","iopub.status.idle":"2025-01-12T19:54:39.219770Z","shell.execute_reply.started":"2025-01-12T19:54:37.468755Z","shell.execute_reply":"2025-01-12T19:54:39.219106Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Assuming `predictions` contains the predicted class indices from your model\n# And `test_data` is the generator used for the test set\n\n# Extract filenames from the test generator\nfilenames = test_data.filenames\n\n# Create a DataFrame for the submission\nsubmission_df = pd.DataFrame({\n    \"filename\": filenames,\n    \"class_id\": predicted_classes\n})\n\n# Ensure formatting matches the required submission format\nsubmission_df[\"filename\"] = submission_df[\"filename\"].str.split(\"/\").str[-1]  # Extract only the file name\nsubmission_df.to_csv(\"submission_basic.csv\", index=False)\n\nprint(\"Submission file created: submission_basic.csv\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:54:39.221787Z","iopub.execute_input":"2025-01-12T19:54:39.222050Z","iopub.status.idle":"2025-01-12T19:54:39.234979Z","shell.execute_reply.started":"2025-01-12T19:54:39.222026Z","shell.execute_reply":"2025-01-12T19:54:39.234228Z"}},"outputs":[{"name":"stdout","text":"Submission file created: submission_basic.csv\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Model Building (Transfer Learning)\nThe basic CNN model I built didn't perform well. That is probabily because of the fact that there are few data to train our model. We solve this problem with using a pretrained model which trained on large datasets. So I will use ResNet50 for this purpose.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\n\n\n# Load Pre-Trained ResNet50\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n\n# Freeze Base Model\nbase_model.trainable = False\n\n# Add Custom Layers\nx = base_model.output\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(256, activation=\"relu\")(x)\nx = layers.Dropout(0.5)(x)\nx = layers.Dense(512, activation=\"relu\")(x)\nx = layers.Dropout(0.5)(x)\noutput = layers.Dense(6, activation='softmax')(x)  # 6 classes\n\n# Create Model\nmodel2 = models.Model(inputs=base_model.input, outputs=output)\n\n# Compile Model\nmodel2.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Callbacks\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T20:18:33.872815Z","iopub.execute_input":"2025-01-12T20:18:33.873157Z","iopub.status.idle":"2025-01-12T20:18:34.883381Z","shell.execute_reply.started":"2025-01-12T20:18:33.873128Z","shell.execute_reply":"2025-01-12T20:18:34.882686Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Training the Model (Transfer Learning)\n\nFirst we just train th layers we added to the base model so that when pre-trained layers are introduced adjust their weights slightly to suit our task better.","metadata":{}},{"cell_type":"code","source":"# Train Model\nhistory = model2.fit(\n    train_data,\n    validation_data=val_data,\n    epochs=30,\n    callbacks=[early_stopping]\n)\n\n# Fine-Tune Base Model\nbase_model.trainable = True\n\n# Recompile with a Lower Learning Rate\nmodel2.compile(\n    optimizer=Adam(learning_rate=1e-5),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Fine-Tune Model\nhistory_fine = model2.fit(\n    train_data,\n    validation_data=val_data,\n    epochs=30,\n    callbacks=[early_stopping]\n)\n\nprint(\"Training complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T20:24:15.800841Z","iopub.execute_input":"2025-01-12T20:24:15.801176Z","iopub.status.idle":"2025-01-12T20:29:18.828003Z","shell.execute_reply.started":"2025-01-12T20:24:15.801149Z","shell.execute_reply":"2025-01-12T20:29:18.827053Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.7810 - loss: 0.5431 - val_accuracy: 0.7375 - val_loss: 0.6337\nEpoch 2/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.7999 - loss: 0.5262 - val_accuracy: 0.7344 - val_loss: 0.6283\nEpoch 3/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.8047 - loss: 0.4914 - val_accuracy: 0.7250 - val_loss: 0.6248\nEpoch 4/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.8089 - loss: 0.4319 - val_accuracy: 0.7500 - val_loss: 0.6403\nEpoch 5/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.8128 - loss: 0.4441 - val_accuracy: 0.7312 - val_loss: 0.6202\nEpoch 6/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.8146 - loss: 0.4478 - val_accuracy: 0.7312 - val_loss: 0.6235\nEpoch 7/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.8230 - loss: 0.4265 - val_accuracy: 0.7531 - val_loss: 0.6018\nEpoch 8/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.8484 - loss: 0.3801 - val_accuracy: 0.7750 - val_loss: 0.5841\nEpoch 9/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.8485 - loss: 0.3857 - val_accuracy: 0.7688 - val_loss: 0.5820\nEpoch 10/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.8585 - loss: 0.3811 - val_accuracy: 0.7750 - val_loss: 0.6234\nEpoch 11/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.8808 - loss: 0.3309 - val_accuracy: 0.7719 - val_loss: 0.6235\nEpoch 12/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.8974 - loss: 0.2802 - val_accuracy: 0.7906 - val_loss: 0.6122\nEpoch 13/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.8846 - loss: 0.3064 - val_accuracy: 0.7781 - val_loss: 0.5772\nEpoch 14/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.8944 - loss: 0.2821 - val_accuracy: 0.7844 - val_loss: 0.5603\nEpoch 15/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.8792 - loss: 0.3295 - val_accuracy: 0.7875 - val_loss: 0.6269\nEpoch 16/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.8965 - loss: 0.2872 - val_accuracy: 0.7906 - val_loss: 0.5648\nEpoch 17/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.9304 - loss: 0.2215 - val_accuracy: 0.7969 - val_loss: 0.5554\nEpoch 18/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.9159 - loss: 0.2278 - val_accuracy: 0.8031 - val_loss: 0.5437\nEpoch 19/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.9368 - loss: 0.1909 - val_accuracy: 0.8062 - val_loss: 0.5628\nEpoch 20/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.9374 - loss: 0.1857 - val_accuracy: 0.8281 - val_loss: 0.5598\nEpoch 21/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.9354 - loss: 0.1838 - val_accuracy: 0.8125 - val_loss: 0.5314\nEpoch 22/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.9437 - loss: 0.1796 - val_accuracy: 0.8094 - val_loss: 0.5377\nEpoch 23/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.9319 - loss: 0.1915 - val_accuracy: 0.8219 - val_loss: 0.5350\nEpoch 24/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.9587 - loss: 0.1409 - val_accuracy: 0.8219 - val_loss: 0.5291\nEpoch 25/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.9543 - loss: 0.1625 - val_accuracy: 0.8156 - val_loss: 0.5384\nEpoch 26/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.9612 - loss: 0.1219 - val_accuracy: 0.8250 - val_loss: 0.5416\nEpoch 27/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.9672 - loss: 0.1257 - val_accuracy: 0.8125 - val_loss: 0.6095\nEpoch 28/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.9629 - loss: 0.1242 - val_accuracy: 0.8156 - val_loss: 0.5648\nEpoch 29/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.9616 - loss: 0.1169 - val_accuracy: 0.8281 - val_loss: 0.5832\nEpoch 30/30\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.9747 - loss: 0.0977 - val_accuracy: 0.8250 - val_loss: 0.5916\nEpoch 1/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 115ms/step - accuracy: 0.9663 - loss: 0.1205 - val_accuracy: 0.8219 - val_loss: 0.5820\nEpoch 2/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.9704 - loss: 0.1032 - val_accuracy: 0.8000 - val_loss: 0.6132\nEpoch 3/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.9666 - loss: 0.1458 - val_accuracy: 0.8000 - val_loss: 0.6515\nEpoch 4/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.9661 - loss: 0.1140 - val_accuracy: 0.8125 - val_loss: 0.6361\nEpoch 5/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.9688 - loss: 0.1280 - val_accuracy: 0.8219 - val_loss: 0.6428\nEpoch 6/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.9786 - loss: 0.0878 - val_accuracy: 0.8250 - val_loss: 0.6584\nEpoch 7/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.9806 - loss: 0.0779 - val_accuracy: 0.8406 - val_loss: 0.6354\nEpoch 8/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.9822 - loss: 0.0730 - val_accuracy: 0.8281 - val_loss: 0.6369\nEpoch 9/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.9774 - loss: 0.1000 - val_accuracy: 0.8469 - val_loss: 0.6438\nEpoch 10/50\n\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.9802 - loss: 0.0853 - val_accuracy: 0.8438 - val_loss: 0.6674\nTraining complete.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Predict on test data\npredictions2 = model2.predict(test_data)\n\n# Convert predictions to class indices\npredicted_classes2 = predictions2.argmax(axis=1)\n\n# Map class indices to class labels\nclass_labels = list(train_data.class_indices.keys())\npredicted_labels = [class_labels[i] for i in predicted_classes]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T20:14:12.490829Z","iopub.execute_input":"2025-01-12T20:14:12.491211Z","iopub.status.idle":"2025-01-12T20:14:15.738878Z","shell.execute_reply.started":"2025-01-12T20:14:12.491182Z","shell.execute_reply":"2025-01-12T20:14:15.737974Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Extract filenames from the test generator\nfilenames = test_data.filenames\n\n# Create a DataFrame for the submission\nsubmission_df = pd.DataFrame({\n    \"filename\": filenames,\n    \"class_id\": predicted_classes2\n})\n\n# Ensure formatting matches the required submission format\nsubmission_df[\"filename\"] = submission_df[\"filename\"].str.split(\"/\").str[-1]  # Extract only the file name\nsubmission_df.to_csv(\"submission_transfer.csv\", index=False)\n\nprint(\"Submission file created: submission_transfer.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T20:14:18.529392Z","iopub.execute_input":"2025-01-12T20:14:18.529729Z","iopub.status.idle":"2025-01-12T20:14:18.538507Z","shell.execute_reply.started":"2025-01-12T20:14:18.529699Z","shell.execute_reply":"2025-01-12T20:14:18.537706Z"}},"outputs":[{"name":"stdout","text":"Submission file created: submission_transfer.csv\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Conclusion\n\nWe started with building a CNN from scratch and it didn't perform well because we have few data. So the model couldn't capture specific features in the dataset. However, we overcame this prblem with using a pre-trained model as our base model and constructing our task specific layers on top of them.","metadata":{}}]}